# Prosthetic Design

![Prosthetic Design Cover](assets/prosthetic_design_cover.png)

[![View on Devpost](https://img.shields.io/badge/Devpost-Project%20Page-blue?logo=devpost)](https://devpost.com/software/t-e5rljs)
ğŸ† **Winner of the Vizcom: Visual Intelligence Award** at the [MCP and A2A Hackathon - AWS Edition](https://lu.ma/vibecode?tk=V8VB1G)

Personalized prosthetics, powered by style. Design a prosthetic leg that feels like **you**.

---

## Inspiration
Our inspiration came from a close friend who needed a prosthetic leg. He wanted something that made him feel happy and reflected his personality, but he struggled to find a company that offered full customization. That experience made us realize how limited the options are for personalized prosthetics, and we wanted to build something to change that.

## What it does
The **Prosthetic Design** web application lets users select stylistic preferencesâ€”â€‹color schemes, patterns, textures, or themesâ€”â€‹through a simple dropdown interface. These preferences are used to generate a one-of-a-kind prosthetic leg design, which is then forwarded directly to a prosthetics manufacturer for production.

## How it works
1. **Vizcom automation** â€“ Vizcom's design AI has no public API, so we built an `Apify` **Actor** (see `my-actor/src/main.py`) that drives Vizcom through a headless **Playwright** browser session. The Actor uploads a source image *or* a text-prompt, waits for Vizcom to generate a 3-D model, and automatically exports a `GLB`/`STL` file.
2. **MCP orchestration** â€“ Mastra **MCP** coordinates multiple agentic components, invoking the Apify Actor and post-processing the result.
3. **Arcade.dev e-mail automation** â€“ When a design is ready, an automated e-mail with the 3-D model attached is sent to the selected prosthetics manufacturer.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     1      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     2      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     3      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Apify Actor â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   MCP Flow    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Arcade.dev     â”‚
â”‚ (Next.js)   â”‚  prompt   â”‚  (Playwright)â”‚  .glb/.stl â”‚  (TypeScript) â”‚  email   â”‚ Manufacturer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## System architecture

![System architecture](assets/system_architecture.png)

### Vizcom automation demo

![Vizcom automation](assets/vizcom-auto.gif)

*The Apify Actor (agent) controls Vizcom headlessly via Playwright, performing all clicks, uploads, and exports without human intervention.*

## Tech stack
- **Python** + **Playwright** + **Apify SDK** for browser automation
- **Mastra MCP** for orchestration / agent framework
- **Arcade.dev** for transactional e-mail
- **Node.js / TypeScript / Next.js** for the web UI
- **Vizcom** generative 3-D design engine

## Repository structure
```
.
â”œâ”€â”€ README.md                â† you are here
â”œâ”€â”€ my-actor/                â† Apify Actor (Python + Playwright)
â”‚   â”œâ”€â”€ src/main.py          â† main automation script
â”‚   â”œâ”€â”€ requirements.txt     â† Python dependencies
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/                â† (optional) Next.js web app â€” not included in this repo
â””â”€â”€ ...
```

## Getting started (local)

### Prerequisites
- Python â‰¥ 3.10
- Node.js â‰¥ 18 (if you plan to run the frontend)
- [Apify CLI](https://docs.apify.com/cli) `npm i -g apify`
- Playwright browsers: `python -m playwright install firefox`

### 1 Â· Clone & install
```bash
git clone https://github.com/your-org/prosthetic-design.git
cd prosthetic-design/my-actor
pip install -r requirements.txt
```

### 2 Â· Configure secrets
Create a `.env` file (or export env-vars) with your Vizcom credentials:
```dotenv
VISCOM_USER=you@example.com
VISCOM_PASSWORD=super-secret
```

### 3 Â· Run the Actor
```bash
# from the my-actor directory
apify run --debug --headed  # headed mode helps when debugging the browser
```
The Actor will upload `leg.png` by default (or download an image when `--imageUrl` is supplied), generate a 3-D model, and export `exported.glb` to the Apify key-value store.

### Optional CLI flags
```bash
--imageUrl <url>    # remote image to use instead of leg.png
--prompt "neon pink cyberpunk pattern"  # combine prompt + image workflow
--headed            # run browser in non-headless mode
--debug             # verbose logging
```

## Deploy to Apify Cloud
```bash
# authenticate once
apify login # paste your API token

# deploy actor from my-actor directory
apify push
```
Then trigger the Actor either via the Apify UI or a simple HTTPS request:
```bash
curl -X POST \
  -d '{"imageUrl":"https://example.com/leg.jpg"}' \
  "https://api.apify.com/v2/acts/<username>~prosthetic-design/run-sync?token=<APIFY_TOKEN>"
```

## Challenges
- **No Vizcom API** â€“ we reverse-engineered the UI and built resilient Playwright selectors with retry logic.
- **Headless browser quirks** â€“ WebGL and dynamic React components required multiple workarounds.

## Accomplishments
- Fully automated Vizcom generation flow with zero manual clicks
- Seamless e-mail hand-off to manufacturers
- End-to-end personalization from user style input to production-ready 3-D model

## What we learned
- Deep dive into Apify's Python SDK and storage primitives
- Coordinating multiple agentic frameworks (Apify, MCP) in a single product

## Sample generated models

![Generated color variants](assets/color_variants.png)

<sub>Four color-way examples</sub>

## Roadmap
- Expand beyond legs: arms, feet, and limb covers
- âœ… Add live 3-D preview in the web UI (three.js)
- Integrate pricing & order-tracking APIs from manufacturers

## License
Distributed under the MIT License. See [`LICENSE`](LICENSE) for more information. 